{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYBpP5M/ifjp2chTf8WhfP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pareshpawar2915-source/build-llm-application/blob/main/list_3.2_tf_idf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weuuQ28Woepe"
      },
      "outputs": [],
      "source": [
        "# TF-IDF Function (example)\n",
        "def tfidf(word, doc_id):\n",
        "    tf = tokenized_docs[doc_id].count(word)  # Term frequency\n",
        "    df = len(index[word]) if word in index else 0  # Document frequency\n",
        "    idf = math.log(len(examples) / (df + 1))  # Inverse document frequency\n",
        "    return tf * idf\n",
        "\n",
        "# Example demonstration using the \"fox\"\n",
        "fox_sentence = \"The quick brown fox jumps over the lazy dog. The fox is quick and the dog is lazy.\"\n",
        "fox_tokens = word_tokenize(fox_sentence)\n",
        "fox_count = fox_tokens.count('fox')\n",
        "total_terms = len(fox_tokens)\n",
        "tf_fox = fox_count / total_terms\n",
        "\n",
        "print('--- TF Example ---')\n",
        "print('Sentence:', fox_sentence)\n",
        "print('Tokenized:', fox_tokens)\n",
        "print(f\"Count of 'fox': {fox_count}; Total terms: {total_terms}; TF(fox) = {tf_fox:.4f}\")\n",
        "\n",
        "# Demo\n",
        "print('\\n--- TF-IDF demo on corpus ---')\n",
        "words_to_check = ['Machine', 'learning', 'neural', 'cats', 'The']\n",
        "for w in words_to_check:\n",
        "    scores = []\n",
        "    for doc_id in range(len(examples)):\n",
        "        score = tfidf(w, doc_id)\n",
        "        if score > 0:\n",
        "            scores.append((doc_id, score))\n",
        "    print(f\"Word: '{w}' --> Scores: {scores}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xRgy_4MAogxi"
      }
    }
  ]
}